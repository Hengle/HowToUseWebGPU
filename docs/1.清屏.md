# 从最简单的清屏开始

首先，我们从最简单的清屏项目开始，学习如何使用 webgpu 执行一个程序，将我们的 canvas 的背景色设置成清屏背景（clearcolor）。

首先，我们可以从 window（或者 worker）的 navigator 上获取 gpu 属性，这个属性是一个 GPU 对象。GPU 对象是整个 WebGPU 的入口（entry point）。所以，我们可以从入口判断浏览器是否支持 webgpu,如果不支持的话，可以给出友好的提示。

```
    const entry: GPU = navigator.gpu;
    if (!entry) {
        document.getElementById("notSupport").style.display = "";
        return;
    }
```

我们继续正常的逻辑，`GPU` 对象包含一个`requestAdapter`的 promise，用来获取一个显卡适配器。我们可以给它传入一个参数，用来表示我们需要的适配器是哪种类型。比如我们笔记本电脑可能包含核显也包含独立显卡。所以这里也会有两个选项可以选择包括`low-power` 和 `high-performance`。

> enum GPUPowerPreference {
> "low-power",
> "high-performance"
> };

```
    // 拿到gpu的适配器（显卡）
    const adapter = await navigator.gpu.requestAdapter({
        powerPreference: "high-performance",
    });
```

对于 adapter 来说，它只是一个抽象的显卡适配器，并不是真的显卡实例，我们可以使用 adapter 的`requestDevice`的方法来获取一个 GPUDevice 的实例。GPUDevice 是整个渲染的核心类，它包含了整个渲染过程中的 command 创建，提交等。

```
    // 适配器获取具体的device实例
    const device: GPUDevice = await adapter.requestDevice();
```

我们继续获取 canvas 对象，并且拿到 context，context 的类型我们选择使用`gpupresent`。这里顺序很重要，有个坑就是我之前有个习惯就是先获取 canvas 对象,拿到 context，然后再初始化其他 webgl 的对象什么的，这里不能先获取 context，否则不显示。

```
    // 获取canvas
    const canvas: HTMLCanvasElement = document.querySelector("#renderCanvas");
    // 这句非常顺序非常重要，不能在获取device之前获取context，否则会canvas不显示图形
    // 只有在dom更新（例如修改canvascss宽高）后才显示
    const context = (<unknown>(
        canvas.getContext("gpupresent")
    )) as GPUCanvasContext;
```

swapchain 的概念和 vulkan 里面的 swapchain 是一致的，其实就是当 CPU 和 GPU 处理能力不一致的时候，它给我们一些策略让我们显示队列中的哪些 buffer。比如在视频帧中我们不希望跳帧，就依次取，渲染场景等情况，我们可以丢弃一些直接显示最新的场景画面。

```
    // 获取swapchain 用于向canvas输出渲染结果
    const format = await context.getSwapChainPreferredFormat(device);
    const swapChain: GPUSwapChain = context.configureSwapChain({
        device: device,
        format: format,
        usage: GPUTextureUsage.OUTPUT_ATTACHMENT,
    });
```

接下来就是正经的绘制工作了,主要是创建 GPUCommandEncoder，然后添加 renderpass，最终推送到 gpu 的执行队列进行执行。

```
    // 创建command生成器 用来编码向gpu发送的command
    const commandEncoder: GPUCommandEncoder = device.createCommandEncoder();

    // 渲染pass的描述
    const backgroundColor = { r: 0.25, g: 0.5, b: 1, a: 1.0 };
    const renderPassDescriptor: GPURenderPassDescriptor = {
        colorAttachments: [
            {
                attachment: swapChain.getCurrentTexture().createView(),
                loadValue: backgroundColor,
            },
        ],
    };

    // 开始渲染pass的命令
    const renderPassEncoder: GPURenderPassEncoder = commandEncoder.beginRenderPass(
        renderPassDescriptor
    );
    renderPassEncoder.setViewport(
        0,
        0,
        canvas.clientWidth,
        canvas.clientHeight,
        0,
        1
    );

    // 结束渲染pass的命令
    renderPassEncoder.endPass();

    // 向GPU推送command
    device.defaultQueue.submit([commandEncoder.finish()]);
```

总结一下，整个流程是：

-   拿到 gpu 的适配器（GPUAdapter）
-   从适配器（GPUAdapter）获取具体的 device 实例(GPUDevice)
-   创建或者从 dom 获取 canvas，拿到 context （contextId 为 gpupresent）
-   从 context 配置 swapchain 用于向 canvas 输出渲染结果
-   创建 command 生成器 用来编码向 gpu 发送的 command
-   开始渲染 pass 的命令
-   结束渲染 pass 的命令
-   向 GPU 推送 command 执行渲染
