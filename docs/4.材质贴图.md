<!--
 * @Author: hongxu.lin
 * @Date: 2020-07-21 17:05:21
 * @LastEditTime: 2020-07-22 14:22:43
-->

# 材质贴图的使用

经过上篇我们讲解如何使用 bindinggroup 来实现 uniform 绑定 mvp 矩阵，从而达到每帧更新旋转动画的效果。这篇我们继续讲下如何在 webgpu 中使用 bindinggroup 来设置采样器以及贴图，从而使我们支持 uv 贴图。

## UV 属性信息

要正确的贴上贴图，我们首先要在之前的数据上加上 uv 属性。

```
// prettier-ignore
const positions = new Float32Array([
    0.5,    -0.5,   0.0, //右下
    -0.5,   -0.5,   0.0, //左下
    -0.5,   0.5,    0.0, //左上
    0.5,    0.5,    0.0, //右上
]);

// Index Buffer Data
// prettier-ignore
const indices = new Uint16Array([
    0, 2, 1,
    0, 3, 2
]);

// uv Vertex Buffer Data
// prettier-ignore
const uvs = new Float32Array([
    1.0, 1.0,   //右下
    0.0, 1.0,   //左下
    0.0, 0.0,   //左上
    1.0, 0.0    //右上
]);
```

如果你之前编写过 opengl 或者 webgl 的程序，对 uv 肯定并不陌生，它代表了贴图的采样方式。不同的系统对 uv 的坐标定义方式不同，对于 webgpu 材质的 uv 坐标中心点在左上角，和图片数据加载的起始位置一样。

官方文档对于坐标系的相关介绍如下：

> WebGPU’s coordinate systems match DirectX and Metal’s coordinate systems in a graphics pipeline.

-   Y-axis is up in normalized device coordinate (NDC): point(-1.0, -1.0) in NDC is located at the bottom-left corner of NDC. In addition, x and y in NDC should be between -1.0 and 1.0 inclusive, while z in NDC should be between 0.0 and 1.0 inclusive. Vertices out of this range in NDC will not introduce any errors, but they will be clipped.

-   Y-axis is down in framebuffer coordinate, viewport coordinate and fragment/pixel coordinate: origin(0, 0) is located at the top-left corner in these coordinate systems.

-   Window/present coordinate matches framebuffer coordinate.

-   UV of origin(0, 0) in texture coordinate represents the first texel (the lowest byte) in texture memory.

![](http://blogstatic.linhongxu.com/webgpu/UVCoordinate.png)

由于 UV 坐标系定义的不同，如果我们按照之前的 uv 排布方式，会发现贴图的 Y 做了翻转。在 webgl 的贴图中，我们也会遇到这种情况，我们一般是使用`gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, 1)`将图片的 y 反转。在 webgpu 中，我们使用 2 中方式来达到材质坐标调整的效果。

一是，简单直接，在传入数据之前，使用左上角为原点 y 向下的 uv 排布方式，或者把 uv 的 y 做个加工将所有的 y 设置为 1-y。

第二种就是在 shader 中使用的时候，使用 `texture(sampler2D(uTexture, uSampler), vec2(vUV.s, 1 - vUV.t) )`

**这里为了 demo 简洁，我直接手动调整了 uv 的数据，采用 webgpu 的标准左上角为原点。**

## shader

要使用贴图，我们需要在 vertex shader 中加入 uv 的 attribute，并且使用 varing 传入 fragment shader。

```
#version 450
layout(set = 0, binding = 0) uniform Uniforms {
    mat4 uProjectionMatrix;
    mat4 uModelViewMatrix;
};

layout(location = 0) in vec3 aPosition;
layout(location = 1) in vec2 aUV;

layout(location = 0) out vec2 vUV;
void main() {
    gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0);
    vUV = aUV;
}
```

在 fragment shader 中，我们使用 uv 获取当前材质采样的颜色值并输出。

```
#version 450
precision highp float;
layout(set=0, binding=1) uniform sampler uSampler;
layout(set=0, binding=2) uniform texture2D uTexture0;
layout(location=0) in vec2 vUV;

layout(location=0) out vec4 fragColor;

void main(){
    fragColor = texture(sampler2D(uTexture0, uSampler), vUV);
}
```

## RenderPipeline 中加入材质

我们在 js 代码中需要向 webgpu 传入两个 BindingGroup 的 entry（unifrom），一个是 sampler，一个是 texture2d。在 renderpipeline 的类中我们加入两个帮助方法`addSampler`、`addTextureView`用来做这些事情。其中 addSampler 比较简单，就是创建 Sampler，指定 binding 的位置即可。

```
addSampler(binding: number, magFilter: GPUFilterMode = "linear", minFilter: GPUFilterMode = "linear") {
        const sampler = this.engin.device.createSampler({
            magFilter: magFilter,
            minFilter: minFilter,
            maxAnisotropy: 4,
        });

        this.addUniformEntry({
            binding: binding,
            visibility: GPUShaderStage.FRAGMENT,
            type: "sampler",
            resource: sampler,
        });
    }
```

添加材质贴图比较复杂，首先要先加载图片，这里使用 HTMLImageElement 的 decode 方法等待图片加载完成。也可以使用 onload 回调，这里只是使用 await 的写法更加简洁。然后创建一个 GPUTexture 对象，设置一些 copy 参数，执行队列的`device.defaultQueue.copyImageBitmapToTexture`方法，copy 图像内容到 texture。最后释放内存数据。我们就完成了对 GPUTexure 的创建和图片映射。

```
async addTextureView(binding: number, url: string, needCors: boolean = true) {
    // 加载图片
    const img = new Image();
    if (needCors) {
        img.crossOrigin = "anonymous";
    }
    img.src = url;
    await img.decode();
    // 生成bitmap
    const bitmap = await createImageBitmap(img);
    // 创建GPUTexture
    const texture = this.engin.device.createTexture({
        size: {
            width: img.width,
            height: img.height,
            depth: 1,
        },
        format: "rgba8unorm",
        usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.SAMPLED,
    });

    // 设置copy的源
    let source: GPUImageBitmapCopyView = { imageBitmap: bitmap };
    // 设置copy到的地方
    let destination: GPUTextureCopyView = { texture: texture };
    // 设置copy的尺寸
    let copySize: GPUExtent3D = {
        width: img.width,
        height: img.height,
        depth: 1,
    };
    // 执行copy操作
    this.engin.device.defaultQueue.copyImageBitmapToTexture(source, destination, copySize);
    // 释放bitmap数据
    bitmap.close();

    this.addUniformEntry({
        binding: binding,
        visibility: GPUShaderStage.FRAGMENT,
        type: "sampled-texture",
        resource: texture.createView(),
    });
}

```

最终我们生成的 BindingGroupLayout 类似如下结构：

```
{
    "entries": [
        {
            "binding": 0,
             "visibility": GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,
             "type": "uniform-buffer"
            },
        {
            "binding": 1,
            "visibility": GPUShaderStage.FRAGMENT,
            "type": "sampler"
        },
        {
            "binding": 2,
            "visibility": GPUShaderStage.FRAGMENT,
            "type": "sampled-texture"
        }
    ]
}

```

BindingGroup 的内容如下：

```
{
    layout:  uniformBindGroupLayout,
    entries:  [
        {
            "binding":0,
            "resource":buffer
        },
        {
            "binding":1,
            "resource":sampler
        },
        {
            "binding":2,
            "resource":textureview
        }
    ]

    ,
}
```

## 主程序中调用

在主程序中我们只需要调用 renderpipeline 的方法加入 sampler 和 texture 就行了，api 非常简洁。

```
pipline.addSampler(1);
await pipline.addTextureView(2, "https://cdn.linhongxu.com/uv_grid_opengl.jpg");
pipline.generatePipline();
```

其余部分和之前主渲染循环，更新模型旋转矩阵的代码保持一致，我们即可以完成对材质贴图的支持了。
